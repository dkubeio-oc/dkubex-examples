# Retrieval-Augmented Generation with LlamaIndex
The data ingestion and evaluation pipeline offers users the flexibility to seamlessly incorporate custom data and perform evaluations on synthetic datasets generated using language models (LLMs). It supports various configurations to tailor the ingestion process and evaluation criteria according to specific user needs.

## Key Features
- **Flexible Data Ingestion:** Users can customize the data ingestion pipeline by selecting their preferred embedding model for generating embeddings and a vector store for storing the resulting vector database. Additionally, various data loaders are supported, allowing users to adapt the ingestion process to their chosen data loader.
- **Retrieval-Augmented Generation (RAG):** The pipeline facilitates RAG on ingested datasets using the language model (LLM) of the user's choice. Different LLMs are supported, enabling users to deploy them based on their preferences.
- **Evaluation Metrics:** The pipeline supports evaluation of synthetic datasets generated by LLMs, including open-source models or those from OpenAI. Metrics such as Mean Reciprocal Rank (MRR), similarity score, and hit rate are utilized for comparing generated datasets against each other.

## Usage
- **Data Ingestion:**
    - Configure the pipeline by selecting embedding models, vector stores, and data loaders according to your requirements.
    - Ingest custom data seamlessly into the pipeline.
      
- **Retrieval-Augmented Generation (RAG):**
    - Choose the desired LLM for performing RAG on ingested datasets.
    - Execute RAG processes as needed.

- **Evaluation:**
    - Compare synthetic datasets generated by different LLMs using evaluation metrics like MRR, similarity score, and hit rate.
    - Analyze the results to assess the performance of LLMs and the quality of generated datasets.
